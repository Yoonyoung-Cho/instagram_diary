import streamlit as st
import json
import re 
import pandas as pd
from datetime import datetime
from datetime import date, timedelta
from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma, FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import DataFrameLoader
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain_community.vectorstores import FAISS
from langchain_milvus import Milvus 
from langchain_core.runnables import ConfigurableField

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain.prompts.chat import HumanMessagePromptTemplate

# st.set_page_config(
#     page_title="ì¸ìƒì˜ í•˜ì´ë¼ì´íŠ¸",
#     page_icon="ğŸ®",
#     # layout="wide",
#     initial_sidebar_state="auto",
# )
 
# Load data 
with open ("../instagram_diary/content/posts_1.json", "r") as f:
    data = json.load(f)
df = pd.DataFrame()
for i in range(len(data)):
    df = pd.concat([df,pd.DataFrame(data[i])])
df = df.map(lambda x: x.encode('latin-1').decode('utf-8') if isinstance(x, str) else x)
df = df.reset_index(drop=True)

#  ì „ì²˜ë¦¬ 
df.loc[df.title.isna(),'creation_timestamp']= [x.get('creation_timestamp') for x in df.loc[df.title.isna()]['media']]
df.loc[df.title.isna(),'title']= [x.get('title').encode('latin-1').decode('utf-8') for x in df.loc[df.title.isna()]['media']]
df['uri'] = df.media.map(lambda x: x['uri'])
df['dt'] = [datetime.fromtimestamp(x) for x in df['creation_timestamp']]
df['year'] = df['dt'].map(lambda x: str(x.year))
df['month'] = df['dt'].map(lambda x: x.month)
df['day'] = df['dt'].map(lambda x: x.day)
df['number'] = df.title.rank(method='dense').astype(int)
df_nodup = df[["title", 'year', 'month', 'day', 'number']].drop_duplicates(keep='last')
df_nodup.reset_index(drop=True).head()



st.set_page_config(
    page_title="ì˜¤ëŠ˜ì˜ í•˜ì´ë¼ì´íŠ¸",
    page_icon="ğŸ®",
    # layout="wide",
    initial_sidebar_state="auto",
)

st.markdown("# ë‚´ ì¸ìƒì˜ í•˜ì´ë¼ì´íŠ¸ ğŸ‰")

st.markdown(f"ì•ˆë…•í•˜ì„¸ìš”! `yooniary` ì¼ê¸°ì¥ì˜ ê²€ìƒ‰ê¸°ì…ë‹ˆë‹¤ğŸ¤— \n í˜„ì¬ ì¼ê¸°ì¥ì—ëŠ” {df_nodup.shape[0]}ê°œì˜ ì¼ê¸°ê°€ ìˆì–´ìš”. ")

year_num = datetime.today().year
month_num = datetime.today().month

st.markdown(f' ### `yooniary`ì˜ {year_num}ë…„ {month_num}ì›” Highlight')

st.markdown("ìµœê·¼ 1ë‹¬ê°„ ê°€ì¥ ì¸ìƒê¹Šì—ˆë˜ ê¸°ì–µì„ ë˜ëŒì•„ ë³´ì„¸ìš”!")

query = "ê°€ì¥ ì¦ê±°ì› ë˜ ì¼ë“¤ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."
# st.text(query)

# vectorstore = Milvus(
#     OpenAIEmbeddings(),
#     connection_args={"uri": "/Users/kakaogames/Documents/GAI/instagram_diary/db/milvus/insta_milvus.db"},
#     collection_name="mulvus_insta_v01",
# )
vectorstore = Milvus(
    OpenAIEmbeddings(),
    connection_args={"uri": "/Users/kakaogames/Documents/GAI/instagram_diary/db/milvus/insta_milvus2.db"},
    collection_name="mulvus_insta_v02",
)

query = 'ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜ ì‚¬ê±´ë³„ë¡œ bullet pointë¡œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.'

retriever = vectorstore.as_retriever().configurable_fields(
    search_kwargs=ConfigurableField(
        id="retriever_search_kwargs",
    )
)

prompt_txt = """ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤. 
contextì—ì„œ ì¼ê¸°ì¥ ë‚´ìš©ì´ ì£¼ì–´ì§€ë©´ ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ì¹œì ˆí•œ ë§íˆ¬ë¡œ ë‹µë³€í•˜ì„¸ìš”.
ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ë§Œ í•˜ë„ë¡ í•˜ê³ , ë§Œì•½ ë‹µì„ ëª¨ë¥¸ë‹¤ë©´, ê·¸ëƒ¥ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì‹­ì‹œì˜¤. 
ë§ì¶¤ë²•ì— ìœ ì˜í•˜ì„¸ìš”.
ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ê³  ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 

Question: {question} 
Context: ë‚˜ëŠ” ê³µë•ìœ¼ë¡œ í‡´ê·¼í–‡ë‹¤ ê·¼ë° ì¼í‡´ë¦¬ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ â€¦ë„ˆë¬´ ì§€ì˜¥ì² ì´ì—‡ì–´ì„œ ë‹¹í™©. ì‚¬ëŒë“¤ ë‹¤ ë°€ê³  ë‚œë¦¬ë„ ì–´ë‹ˆì—‡ë‹¤. ì•½ê°„ í”¼ê³¤í•œì±„ë¡œ ê³µë•ë„ì²™í–‡ëŠ”ë° ì¹œêµ¬ë‘ ë¬´ã…œë¨¹ì§€í•˜ë‹¤ê°€ ê·¸ë•Œ ëª»ë¨¹ì€ ë–¡ê°ˆë¹„ ê°€ ì•„ë‹ˆë¼ ë¶ˆê³ ê¸° ê°€ì–µí•´ë‚´ê³  ë¶ˆê³ ê¸° ë¨¹ìœ¼ëŸ¬ëŒ ëƒ ëƒ  ì •ë§ ë§›ì‡ì—‡ë‹¤ ë‚™ì§€ê°€ ì²˜ìŒì— ì˜ëª»ë‚˜ì™€ì„œ ì¢€ ë‹¹ë¢í•´ã…›ì§€ë§Œ ë§›ì‡ì—‡ì–´ ë§¤ìš´ ë¶ˆê³ ê¸°ë„ ë§›ì‡ì—‡ë”” ê·¼ë° ê½¤ë§¤ì›ŸìŒ ê·¸ëŸ¬ê³  ë§ˆëŠ˜ì´ã…‹ã…‹ã…‹ã…‹ë„ˆë¬´ë§¤ì›Œ ë¯¸ì³£ë‹¤ì´ë ‡ê²Œ ë§ˆìš´ ë§ˆëŠ˜ ì§„ì§œ ë„ˆë¬´ ë§¤ì›Œâ€¦.ë§ë˜ë‚˜ ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìœ ã…—ã……ë‹¤. ì¹œêµ¬ë‘ ìš¸ë©´ì„œ ë¨¹ë‹¤ê°€ ë‚˜ì™€ì„œ 2ì°¨ë¡œ ë–¡ë³¶ì´ ìˆœëŒœë¨¸ê¸ˆ. ë¨¹ìš°ë©´ì„œ íšŒì‚¬ ì–˜ê¸°ì«Œ ë˜ì¥¬ê³ ~ê·¸ëŸ¬ê³  í•œê°• ì‚°ì±…í•˜ëŸ¬ê³  í•«ëŠ”ë° ë§‰ìƒ ë„ì°©í•˜ë‹ˆ í•˜ê¸°ì‹«ê³  í”¼ê³¤í•´ì„œ ì§‘ì— ê°“ë‹¤. ì•Œê³ ë³´ë‹ˆ ë‚˜ ì˜¤ëŠ˜ ê°‘ìƒì„ ì•½ ì•ˆë¨¸ê¸ˆ ì •ë§ ê·€ì‹ ê°™ì€ ëª¸ìƒíƒœì•¼ ê°‘ìƒì„ ì€ ì¤‘ìš”í•œê±°êµ¬ë‚˜ ì‹¶ìŒ ì•„ ë³‘ì›ë„ ë‹¤ë…€ì™”ë‹¤ ì´ê±° ì‹¤ë¹„ ì‹ ì²­í•˜ë©´ ì•ˆë˜ëŠ”ê±°ì˜€ë‚˜? ì—¬íŠ¼ ì•„íŒŒì„œ ìŠ¬í”„ë‹¤ ì™œ ì•ˆë‚«ëŠ”ê±°ì•¼â€¦ \n\n ì–´ì—ì—ì—¥ ë‚˜ ì¼ê¸°ì»ëŠ”ë° ì˜¤ëŠ˜ ì–´ã… ì—†ì–´ì¡‹ì§€. ì•ˆì»ë‚˜? ì˜ì¡°ì›Œ ì—°í™”ë‘ ì ì‹¬ë¨¹ìš´ë‚  ì•„ì¹¨ì€ ìœ ì¦ˆì½”ì‡¼ë‘ ì¹˜ì£¼ê¹€ë°¥ ì¡´ë§› ì ì‹¬ ë§›ì‡ì—‡ê³  ì¬ë°‹ì—‡êµ¬ í‹°íƒì€ ì¡°ê¸ˆ í˜ë“¤ì—ˆê³  ì§‘ê°€ê³ ì‹¶ì—‡ê³ ~ì‹ë‹¨ ê¸°ë¡ì€ ë§í•´ì¨ ê±¸êµ­ ì•ˆí•¨. 
Answer: ### ğŸ“Œ ê³µë•ì—ì„œì˜ í•˜ë£¨ \n\n ê³µë•ìœ¼ë¡œ ì§€ì˜¥ì² ì„ íƒ€ê³  í‡´ê·¼ì„ í–ˆë˜ ë‚ ì…ë‹ˆë‹¤. ì¹œêµ¬ë‘ ì•„ì£¼ ë§¤ìš´ ë¶ˆê³ ê¸°ë¥¼ ë¨¹ì—ˆê³  í•¨ê»˜ ë¨¹ì€ ë§ˆëŠ˜ë„ ì •ë§ ë§¤ì› ìŠµë‹ˆë‹¤. ë„ˆë¬´ ë§¤ì›Œì„œ ìš¸ë©´ì„œ ë¨¹ë‹¤ê°€ ë–¡ë³¶ì´ì™€ ìˆœëŒ€ë¡œ 2ì°¨ë¥¼ ê°”ê³ , ì‚°ì±…ì„ ê°€ë ¤ê³  í–ˆìœ¼ë‚˜ í”¼ê³¤í•´ì„œ ê·¸ëƒ¥ ì§‘ìœ¼ë¡œ ê°”ìŠµë‹ˆë‹¤. ### ğŸ“Œ ì˜ì¡°ì›Œì—°í™”ë‘ ì ì‹¬ ë¨¹ì€ ë‚  \n\n ì•„ì¹¨ì€ ìœ ì£¼ì½”ì‡¼ì™€ ì¹˜ì¦ˆê¹€ë°¥ì„ ë¨¹ì—ˆê³  ì ì‹¬ì€ ì˜ì¡°ì›Œì—°í™”ì™€ ë§›ìˆê²Œ ë¨¹ì—ˆìŠµë‹ˆë‹¤. ì‹ë‹¨ê¸°ë¡ì€ ì•ˆí–ˆìŠµë‹ˆë‹¤.

Question: {question} 
Context: {context} 
Answer:
"""

prompt=ChatPromptTemplate(input_variables=['context', 'question'],
                   messages=[HumanMessagePromptTemplate(
                       prompt=PromptTemplate(input_variables=['context', 'question'], 
                                             template=prompt_txt))])


llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

expr_txt = f"month == {month_num} && year == '{year_num}'"

llm_response = rag_chain.with_config(
    configurable={
        "retriever_search_kwargs": dict(
            expr=expr_txt,
        )
    }
).invoke(query)

st.markdown(llm_response)





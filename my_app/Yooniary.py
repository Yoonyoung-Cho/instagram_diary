import streamlit as st
import json
import re 
import pandas as pd
from datetime import datetime
from datetime import date, timedelta
from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma, FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import DataFrameLoader
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain_community.vectorstores import FAISS

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain.prompts.chat import HumanMessagePromptTemplate

# st.set_page_config(
#     page_title="ì¸ìƒì˜ í•˜ì´ë¼ì´íŠ¸",
#     page_icon="ğŸ®",
#     # layout="wide",
#     initial_sidebar_state="auto",
# )
 
# Load data 
with open ("../instagram_diary/content/posts_1.json", "r") as f:
    data = json.load(f)
df = pd.DataFrame()
for i in range(len(data)):
    df = pd.concat([df,pd.DataFrame(data[i])])
df = df.map(lambda x: x.encode('latin-1').decode('utf-8') if isinstance(x, str) else x)
df = df.reset_index(drop=True)

#  ì „ì²˜ë¦¬ 
df.loc[df.title.isna(),'creation_timestamp']= [x.get('creation_timestamp') for x in df.loc[df.title.isna()]['media']]
df.loc[df.title.isna(),'title']= [x.get('title').encode('latin-1').decode('utf-8') for x in df.loc[df.title.isna()]['media']]
df['uri'] = df.media.map(lambda x: x['uri'])
df['dt'] = [datetime.fromtimestamp(x) for x in df['creation_timestamp']]
df['year'] = df['dt'].map(lambda x: str(x.year))
df['month'] = df['dt'].map(lambda x: x.month)
df['day'] = df['dt'].map(lambda x: x.day)
df['number'] = df.title.rank(method='dense').astype(int)
df_nodup = df[["title", 'year', 'month', 'day', 'number']].drop_duplicates(keep='last')
df_nodup.reset_index(drop=True).head()



st.set_page_config(
    page_title="ì˜¤ëŠ˜ì˜ í•˜ì´ë¼ì´íŠ¸",
    page_icon="ğŸ®",
    # layout="wide",
    initial_sidebar_state="auto",
)

st.markdown("# ë‚´ í•˜ë£¨ì˜ í•˜ì´ë¼ì´íŠ¸ ğŸ‰")

st.markdown(f"ì•ˆë…•í•˜ì„¸ìš”! `yooniary` ì¼ê¸°ì¥ì˜ ê²€ìƒ‰ê¸°ì…ë‹ˆë‹¤ğŸ¤— \n í˜„ì¬ ì¼ê¸°ì¥ì—ëŠ” {df_nodup.shape[0]}ê°œì˜ ì¼ê¸°ê°€ ìˆì–´ìš”. ")

st.markdown(' ### `yooniary`ì˜ 2024 7ì›” Highlight')

st.markdown("ì§€ë‚œ 1ë‹¬ê°„ ê°€ì¥ ì¸ìƒê¹Šì—ˆë˜ ê¸°ì–µì„ ë˜ëŒì•„ ë³´ì„¸ìš”!")


# today = date.today()
# year = str(today.year)
# month = today.month
# today_date = today.day
# # tmp_list = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','19','20','21','22','23','24']
# tmp_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,19,20,21,22,23,24]
# # data = df_nodup.loc[((df_nodup.year=='2024') & (df_nodup.month==7) & (df_nodup.day.isin(tmp_list)))]
# data = df_nodup.loc[((df_nodup.year==year) & (df_nodup.month==month) & (df_nodup.day.isin(tmp_list)))]



# loader = DataFrameLoader(data, page_content_column="title")
# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)
# split_docs = loader.load_and_split(text_splitter=text_splitter)
# vectorstore = FAISS.from_documents(documents=split_docs, embedding= HuggingFaceBgeEmbeddings())
# vectorstore.save_local('./db/highlights/faiss_hugging')
# # vectorstore = FAISS.load_local('../db/faiss', HuggingFaceBgeEmbeddings(), allow_dangerous_deserialization=True)
# vectorstore = FAISS.load_local('../db/faiss_openai', OpenAIEmbeddings(), allow_dangerous_deserialization=True)

# k = 6
# bm25_retriever = BM25Retriever.from_documents(split_docs)
# bm25_retriever.k = k
# faiss_retriever = vectorstore.as_retriever(search_kwargs={"k": k})
# ensemble_retriever = EnsembleRetriever(
#     retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]
# )

# # prompt = hub.pull("rlm/rag-prompt")

# prompt_txt = """ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤. 
# ì§ˆë¬¸ì— ë‹µë³€ì€ ê²€ìƒ‰ëœ ì¼ê¸°ì¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”. 
# ë§Œì•½ ë‹µì„ ëª¨ë¥¸ë‹¤ë©´, ê·¸ëƒ¥ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì‹­ì‹œì˜¤. 
# ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ê³  ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 

# Question: {question} 
# Context: {context} 
# Answer:
# """

# prompt=ChatPromptTemplate(input_variables=['context', 'question'],
#                 #    metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'},
#                    messages=[HumanMessagePromptTemplate(
#                        prompt=PromptTemplate(input_variables=['context', 'question'], 
#                                              template=prompt_txt))])


# llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# def format_docs(docs):
#     # ê²€ìƒ‰í•œ ë¬¸ì„œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
#     return "\n\n".join(doc.page_content for doc in docs)

# rag_chain = (
#     {"context": ensemble_retriever | format_docs, "question": RunnablePassthrough()}
#     | prompt
#     | llm
#     | StrOutputParser()
# )

# response = rag_chain.invoke({'context':data, 'question':"ê°€ì¥ ì¸ìƒê¹Šì€ ì¼ ëª‡ê°€ì§€ë¥¼ ê¼½ì•„ 20ì¤„ ë‚´ì™¸ì˜ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."})




#https://discuss.streamlit.io/t/how-to-display-a-list-of-images-in-groups-of-10-50-100/32935

import pandas as pd 
import json
import streamlit as st
import glob
from datetime import datetime

# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from dotenv import load_dotenv

# API í‚¤ ì •ë³´ ë¡œë“œ
load_dotenv()


from langchain import hub
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma, FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain.prompts.chat import HumanMessagePromptTemplate


st.markdown('# ì¼ê¸°ì¥ ê²€ìƒ‰ê¸° ğŸ”')
st.markdown('ì¼ê¸° ì‘ì„± ê¸°ê°„ê³¼ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì„œ ì¼ê¸°ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!')


# Load data 
with open ("../instagram_diary/content/posts_1.json", "r") as f:
    data = json.load(f)
df = pd.DataFrame()
for i in range(len(data)):
    df = pd.concat([df,pd.DataFrame(data[i])])
df = df.map(lambda x: x.encode('latin-1').decode('utf-8') if isinstance(x, str) else x)
df = df.reset_index(drop=True)

#  ì „ì²˜ë¦¬ 
df.loc[df.title.isna(),'creation_timestamp']= [x.get('creation_timestamp') for x in df.loc[df.title.isna()]['media']]
df.loc[df.title.isna(),'title']= [x.get('title').encode('latin-1').decode('utf-8') for x in df.loc[df.title.isna()]['media']]
df['uri'] = df.media.map(lambda x: x['uri'])
df['dt'] = [datetime.fromtimestamp(x) for x in df['creation_timestamp']]
df['year'] = df['dt'].map(lambda x: str(x.year))
df['month'] = df['dt'].map(lambda x: x.month)
df['day'] = df['dt'].map(lambda x: x.day)
df['number'] = df.title.rank(method='dense').astype(int)
df_nodup = df[["title", 'year', 'month', 'day', 'number']].drop_duplicates(keep='last')
df_nodup.reset_index(drop=True).head()

keyword = st.text_input("ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.", '----') 
year = st.multiselect("ê¸°ê°„ ì„ íƒ",
               list(df.year.unique()),
               list(df.year.unique())[0:1],)

# search_click = st.button('ê²€ìƒ‰í•˜ê¸°')

# if search_click:
data = df_nodup.loc[df_nodup.year.isin(year),:]
data_index = data.title.map(lambda x: keyword in x)
data = data[data_index]
data = data[['number', 'title', 'year', 'month', 'day']]
# st.dataframe(data)


# manuscripts = st.multiselect("ì¼ê¸° ì„ íƒ", data.title, data.title)
# paths = df.loc[df.title.isin(manuscripts),'uri']
# paths = [s for s in paths if "jpg" in s] 

# n = st.number_input("Select Grid Width", 5, 10, 6)

# groups = []
# for i in range(0, len(paths), n):
#     groups.append(paths[i:i+n])

# for group in groups:
#         cols = st.columns(n)
#         for i, image in enumerate(group):
            
#             cols[i].image(f"../instagram_diary/{image}")

# txt = data.loc[data.title.isin(manuscripts),'title'].reset_index(drop=True)[0]
# diary_txt = st.text_area("ì¼ê¸°ë‚´ìš©", txt, label_visibility='hidden', height=400)

# try : 
#     for group in groups:
#         cols = st.columns(n)
#         for i, image in enumerate(group):
            
#             cols[i].image(f"../instagram_diary/{image}")

#     txt = data.loc[data.title.isin(manuscripts),'title'].reset_index(drop=True)[0]
#     diary_txt = st.text_area("ì¼ê¸°ë‚´ìš©", txt, label_visibility='hidden', height=400)
# except: pass


# ì¼ê¸° ì œëª© ìš”ì•½ 
prompt_txt = """ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì‘ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì¼ê¸°ì¥ ë°ì´í„°ì˜ ì œëª©ì„ ì§€ì–´ì£¼ì„¸ìš”. 
8ê¸€ì ì´ë‚´ì˜ ì œëª©ì„ ì‘ì„±í•˜ê³ , ë§¥ë½ì— ë§ëŠ” ì œëª©ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
ì œëª©ë§Œì„ ë‹µë³€ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”. ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ê³  ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 

Question: contextì˜ ì¼ê¸°ì˜ ì œëª©ì„ ì§€ì–´ì£¼ì„¸ìš”. 
Context: ë§›ì‡ì—‡ë˜ ì•„ì›ƒë°±í—ˆã…£ì‹ ê°€ë ¤ê³ í• ë•Œ ì—†ëŠ”@ì¹¸íƒ€ì¹´ë“œë¡œ êµ¬ì§ˆêµ¬ì§ˆí•˜ê²Œ ì¬ê²°ì œí•˜ëŸ¬ê°€ì•¼í•´ì„œ ì›ƒê²»ë‹¤ íŒŒí‹°ê³„ì‹œë‹ˆê¹Œ ë¶„ìœ„ê¸°ê°€ë§ì´ ë‹¬ë¼ì ¸ì„œ ë„ˆë¬´ ì¢‹ë‹¤ íŒŒ í‹° ì¡° ì•„
Answer: íŒŒí‹° ì¢‹ì•„

Question: {question} 
Context: {context} 
Answer:
"""

prompt=ChatPromptTemplate(input_variables=['context', 'question'],
                #    metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'},
                   messages=[HumanMessagePromptTemplate(
                       prompt=PromptTemplate(input_variables=['context', 'question'], 
                                             template=prompt_txt))])

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)



rag_chain2 = (
        # {"context": data.title.reset_index(drop=True)[i], "question": RunnablePassthrough()}
        prompt
        | llm
        | StrOutputParser()
    )

summary = []
for i in range(0,len(data.title)):
    response = rag_chain2.invoke({'context':data.title.reset_index(drop=True)[i], 'question':"ì¼ê¸°ì˜ ì œëª©ì„ ì§€ì–´ì£¼ì„¸ìš”."})
    summary.append(response)
    
title_summary = pd.concat([pd.DataFrame(summary, columns=['summary']), data.title.reset_index(drop=True)], axis=1)


df_tmp = pd.merge(df, title_summary, on='title')
manuscripts = st.multiselect("ì¼ê¸° ì„ íƒ", summary, summary)
title_index = title_summary.loc[title_summary.summary.isin(manuscripts),'title'].to_list()

paths = df_tmp.loc[df_tmp.title.isin(title_index),'uri']
paths = [s for s in paths if "jpg" in s] 

n = st.number_input("Select Grid Width", 5, 10, 6)

groups = []
for i in range(0, len(paths), n):
    groups.append(paths[i:i+n])
    
for group in groups:
        cols = st.columns(n)
        for i, image in enumerate(group):
            
            cols[i].image(f"../instagram_diary/{image}")
            
if len(df_tmp.loc[df_tmp.summary.isin(manuscripts),'title'].unique())!=0 :
    txt = df_tmp.loc[df_tmp.summary.isin(manuscripts),'title'].unique()[0]
    diary_txt = st.text_area("ì¼ê¸°ë‚´ìš©", txt, label_visibility='hidden', height=400)



# ì°¸ê³  : https://www.youtube.com/watch?v=GG6WDeLmw6w
# https://github.com/wjbmattingly/youtube-streamlit-image-grid/blob/main/demo.py
# https://wikidocs.net/235091